\documentclass[11pt,bookmarks,bookmarksnumbered,naturalnames,plainpages=false,pdftex,colorlinks=true,urlcolor=blue,bookmarksdepth=subsection,plainpages=false]{paper}
\usepackage[T2A,T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage[a4paper,margin=1in]{geometry}
% \newcommand{\Be}{\mbox{\usefont{T2A}{\rmdefault}{m}{n}\CYRB}}
\usepackage{times}
\usepackage{amssymb}
\usepackage{transparent}
% \usepackage{makeidx}
\usepackage{tikz}
%\usepackage{wrapfig}
%\usetikzlibrary{snakes,arrows,shapes,automata}
%\usepackage{mlbook}
%\usepackage[round]{natbib}
%\usepackage{multicol}        
\usepackage{epsfig}
\usepackage{graphicx}
% \usepackage{xypic}
\usepackage[matrix,arrow]{xy}
\usepackage[pdftex,colorlinks=true,urlcolor=blue,bookmarksdepth=subsection,plainpages=false]{hyperref}
\usepackage[backend=biber,natbib,style=authoryear]{biblatex}
\def\stackrel#1#2{\mathrel{\mathop{#2}\limits^{#1}}}
\makeatletter
\newcommand{\dashedrightarrow}[1][2pt]{%
  \settowidth{\@tempdima}{$\rightarrow$}\rightarrow% typeset arrow
  \makebox[-\@tempdima]{\hskip-1.5ex\color{white}\rule[0.5ex]{#1}{2pt}}% typeset overlay
  \phantom{\rightarrow}% advance appropriate horizontal distance
}
\makeatother

\newcommand{\andras}[1]{{\color{magenta}{AK: #1}}}
\newcommand{\zalan}[1]{{\color{red}{MM: #1}}}

\addbibresource{ml.bib}

\begin{document} 
\title{The syntax of 4lang definitions}
\author{Andr\'as Kornai}
%\small HAS Computer and Automation Research Institute\\
%\small H-1111 Budapest Kende u 13-17, Hungary\\
%\small \href{mailto:andras@kornai.com}{andras@kornai.com}}
\date{}
\maketitle

\begin{abstract}
We describe how the basic lexicographic principles of 4lang are reflected in
the syntax of definitions
\end{abstract}

\section*{Background}

4lang is a concept dictionary, intended to be universal in a sense made more
precise below. The main motivation was spelled out in \citep{Kornai:2010}
as follows:

``In creating a formal model of the lexicon the key difficulty is the
circularity of traditional dictionary definitions -- the first English
dictionary, \cite{Cawdrey:1604} already defines {\it heathen}
as {\tt gentile} and {\it gentile} as {\tt heathen.} The problem has already
been noted by Leibniz (quoted in \cite{Wierzbicka:1985}):

\begin{quote}
Suppose I make you a gift of a large sum of money saying you can collect it
from Titius; Titius sends you to Caius; and Caius, to Maevius; if you continue
to be sent like this from one person to another you will never receive
anything.
\end{quote}

\noindent
One way out of this problem is to come up with a small list of primitives, and
define everything else in terms of these.'' 

To take the first tentative steps towards language-independence, the system
was set up with bindings in four languages, representative samples of the
major languge families spoken in Europe: Germanic (English), Slavic (Polish),
Romance (Latin), and Finno-Ugric (Hungarian). Today, bindings exist in over 40
languages \citep{Acs:2013}  but the user should keep in mind that these 
bindings provide only rough semantic correspondence to the intended concept. 

4lang can be used for a variety of purposes: for better understanding of
deep cases \citep{Makrai:2014}; for producing state of the art results on
analogy tasks \citep{Recski:2016c}; for studies of the importance of
individual concepts \citep{Makrai:2013a}; for investigating spreading
activation \citep{Nemeskey:2013}; and of course for investigating various
issues of lexicography \citep{Kornai:2015a}.

Unfortunately, these papers don't always reference the same version of the
slowly evolving 4lang, and the principles undergirding the system are not
available in a single, convenient source. The goal of this document is to
provide a single entry point for both the linguistic and the computational
aspects. 

The main {\tt 4lang} file is divided into 9 tab-separated fields, of which the
last is reserved for comments. The percent sign is also used to delimit
comments, this is not (yet) consistent. A typical entry (written as one line
in the file but here broken up in three for legibility) would be

\begin{verbatim}
attention	figyelem	animi_attentio	uwaga	801	u	V    
listen, see, =AGT think =PAT[interesting, important] 
%light verb, "pay attention"
\end{verbatim}

\noindent
As can be seen, the first four columns are the 4 language bindings given in
EHLP order, with provisions for keeping the entire file in 7-bit ASCII. The
fifth is a unique number per concept, most important when the English bindings
coincide: 

\begin{verbatim}
cook	fo3z	coquo	gotowac1	825	u	V	=AGT make <food>, INSTRUMENT heat	
cook	szaka1cs	coquus	kucharz	2152	u	N	person, <profession>, make food		
\end{verbatim}

\noindent
The sixth column is technical (representing current update status) and will be
ignored here, as it is relevant only for the maintainers of the
dictionary. The seventh column is a rough lexical category symbol, see
Section~\ref{lexcat} for further discussion. The main subject of this note is
the 8th column, which gives the 4lang definition, see Section~\ref{8thcol}, 
but before turning to that, we discuss some of the lexicographic
principles. 


%ring	cseng	tinnit	dzwonic1	2735	u	U	bell make sound/993, FOR/2782 attention, <bell PART_OF telephone>	


\section{Lexicographic principles}

\subsection{Reductivity}

In many ways, 4lang is a logical outgrowth of modern, computationally oriented
lexicographic work beginning with Collins-COBUILD \citep{Sinclair:1987}, the
Longman Dictionary of Contemporary English (LDOCE) \citep{Boguraev:1989},
WordNet \citep{Miller:1995}, FrameNet \citep{Fillmore:1998}, and VerbNet
\citep{Kipper:2000}. 

The key step in minimizing circularity was taken in LDOCE, where a small
(about 2,200 words) defining vocabulary (called LDV, Longman Defining
Vocabulary) was created, and strictly adhered to in the definitions with one
trivial exception: words that often appear in definitions (e.g. the word {\it
  planet} is common to the definition of Mercury, Mars, Venus, \ldots) can be
used as long as their definition is strictly in terms of the LDV.  Since {\it
  planet} is defined `a large body in space that moves around a star' and
{\it Jupiter} is defined as `the largest planet of the Sun' it is easy to
substitute one definition in the other to obtain for Jupiter the definition
`the largest body in space that moves around the Sun'. 

4lang generalizes this process, starting with a core list of NNN primitives,
defining a larger set in terms of these, a yet larger set in terms of these,
and so on until the entire vocabulary is in scope. As a practical matter we
started from the opposite direction, with a seed list of approximately 3,500
entries composed of the LDV (2,200 entries), the most frequent 2,000 words
according to the Google unigram count \citep{Brants:2006} and the BNC
\citep{Burnard:1998}, as well as the most frequent 2,000 words from Polish
\citep{Halacsy:2008} and Hungarian \citep{Kornai:2006}.  Since Latin is one of
the four languages supported by 4lang, we added the classic
\cite{Diederich:1939} list and \citep{Whitney:1885}. 

Based on these 3,500 words, we reduced the defining vocabulary by means of a
heuristic graph search algorithm \citep{Acs:2013} that eliminated all words
that were definable in terms of the remaining ones. The end-stage is a
vocabulary with the {\it uroboros property}, i.e. one that is minimal wrt this
elimination process. This list (1,200 words, counting different senses with
multiplicity) was published as Appendix~4.8 of \cite{Kornai:2019} and was used
in several subsequent studies including \citep{Nemeskey:2018}. (The last
remnant of the fact that we started with over 3k words is that numbers in the
5th column are still in the 1-3,500 range, as we decided against renumbering
the set.)

Importantly, since the uroboros vocabulary was obtained by systematic
reduction of a superset of the LDV, it is still guaranteed that every sense of
every word listed in LDOCE (over 82k entries) are definable in terms of
these. Since the defining vocabularies of even larger dictionaries such as
Webster's 3rd \citep{Merriam:1961} are generally included in LDOCE, we have
every reason to believe that the entire vocabulary of English, indeed the
entire vocabulary of any language, is still definable in terms of these 1,200
concepts. 

Unfortunately, such redefinition generally requires more than string
substitution: for example if you substitute `a large body in space that moves
around a star' into `the largest \_\_ of the Sun' you would obtain `the
largest a large body in space that moves around a star of the Sun' and it
takes a great deal of sophistication for the substitution algorithm to realize
that {\it a large} is subsumed by {\it the largest} or that {\it a star} is
instantiated by {\it the Sun}. People perform these operations with ease,
without conscious effort, but for now we lack parsers of the requisite
syntactic and semantic sophistication to do this automatically. Part of our
goal with the strict definition syntax that replaces English syntax on the
right-hand side (rhs) of definitons is to study the mechanisms required by an
automated parser for doing this. 

\subsection{Morphological prerequisites}

The LDV contains a few dozen bound morphemes, the prefixes {\it -able -al -an
  -ance -ar -ate -ation -dom -ed -en -ence -er -ess -est -ful -hood -ible -ic
  -ical -ing -ion -ish -ist -ity -ive -ization -ize -less -like -ly -ment
  -ness -or -ous -ry -ship -th -ure -ward -wards -work -y} and the suffixes
{\it counter- dis- en- fore- im- in- ir- mid- mis- non- re- un- vice- well-}.
These are tremendously useful both in reducing the size of the defining
vocabulary (since {\it eat} and {\it eating} no longer be listed both) and in
making the definitions less complicated. 

While we obviously cannot cover the entirety of English morphology as part of
4lang, we do not consider the problems raised by bound forms to be
qualitatively different from those raised by lexical semantics in
general. Also, languages are not uniform in where they draw the bound/free
boundary: many concepts that are expressed by affixation in one are expressed
by free forms in another, and dictionary definitions often contain these.

We will illustrate our methods on the suffix {\it -ize}, which means something
like `to cause to become', so {\it Americanize} `cause to become American',
{\it carbonize} `cause to become carbon' and so forth. There are cases that do
not fit this analysis ({\it agonize} doesn't mean `cause to become agony' the
same way {\it colonize} means `cause to become colony') and there are other
subregularities one may wish to consider, but the majority of the 2-300
English words ending in {\it -ize} fit this pattern well enough to consider it
the leading candidate for a semantic definition. What we wish to state is a
lexical rule roughly of the following form: for stem X, stem+ize means `cause
to become (like) X'. Anticipating several notational conventions that will
only be explained subsequently, we could write this as 

\begin{verbatim}
-ize CAUSE {become <like/1701> stem}, "-ize" MARK stem
\end{verbatim}

\noindent 
(From here on we keep only the English binding for the definiendum, followed
by the definiens.) Here {\tt CAUSE} is a primitive (part of our eventual
uroboros set) written in CAPS because it is one of the few binary relations we
admit as primitives (primitive unaries and variadic predicates are written
lowercase).  The curly braces (see Section~\ref{parens}) denote a single
hypergraph node (pictorially, all formulas will correspond to hypergraphs) and
the angled brackets signify optionality, enclosing the default option (see
Section~\ref{default}). {\tt MARK} is another primitive, standing for the
relation between signifier (a string, given in doublequotes) and the relevant
element to be substituted, here the node {\tt stem} which is analogous to the
variable X used above. 

However, neither {\tt like/1701} nor {\tt become} are primitives (for the
four-digit disambiguation number following the English binding see
Section~\ref{comma}). {\tt like/1701} `sicut' is defined as {\tt similar} (as
opposed to {\tt like/3382} `amo') and {\tt become} is defined as {\tt
  =AGT[=PAT[after]]} which for now we will paraphrase as `afterwards, agent
IS\_A patient' (thematic roles are discussed in Sections~\ref{agtpat} and
\ref{deepcase}). For something like {\it John caramelized the sugar} this 
would be `John caused the sugar to be <similar to> caramel afterwards'. 

Here, For the sake of readability, we made some consessions to English syntax,
by adding agreement morphology, an article, a copula, and a preposition, but
eventully the reader will get familiar with the syntax of definitions that
lacks all this niceties, and would read {\tt John CAUSE after {sugar <similar>
    caramel}}. 


Since {\tt similar} is not a primitive of the formal language of definitions,
we can take this further by substituting its definition 

\begin{verbatim}
similar =AGT HAS property, =PAT HAS property, "to/2743" MARK =PAT
\end{verbatim}

\noindent
Since named nodes are unique in definitions, what this means is that in the
construction {\it X (is) similar to Y} the agent will have the {\it same}
property as the patient. As expected, the {\tt MARK} relation is
language-specific, for Hungarian we would want to say that the allative case
{\it hoz/hez/h\"{o}z} marks the patient. (4lang currently gives the MARKs only
for English.) 

At this point we can omit the default (since it is a binary realtion, this
means substituting {\tt IS\_A}) or we can expand it, to yield 

\begin{verbatim}
-ize CAUSE {after {=PAT HAS property, stem HAS property}}, "-ize" MARK stem
\end{verbatim}

\noindent At this point, all our notions are primitives, including the
metalinguistic placeholder "stem" and the term {\tt property}, which is really
underspecified as to what property it refers to, as befits the definition of
{\it similar} which is underspecified exactly in this respect (compare {\it
  similar consequences} to {\it similar balloons}). {\tt HAS} again is
primitive, the causative element in {\it -ize} is well known
\citep{Lieber:1992,Plag:1998}, and the idea that we define certain verbs by
their result state is standard. 


\section{Encyclopedic knowledge}

In the fourth edition \citep{Bullen:2003} LDOCE defines {\it caramelize} as
`if sugar caramelizes, it becomes brown and hard when it is heated'. 

\citep{Procter:1978}


as `burnt sugar used for giving food a special
taste and colour' 

{\it sugar} `a sweet white or brown substance that is obtained from plants and
used to make food and drinks sweet' 

Theory of time, verbs, lexical categories, subcategorization
















such as the adverbial-forming {\it -ly}, the noun-forming {\it -ness}, or the
superlative {\it -est}.






\section{The syntax of definitions}\label{8thcol}

\subsection{Coordination}\label{comma}

A 4lang definition always contains one or more (hypergraph) nodes, of which
one is distinguished as the {\it head} (related to, but not exactly the same
as the {\it root} in dependency graphs). All these are interpreted as graph
edges with label 0 running from the defniendum to the definiens.  The simplest
definitions are therefore of the form x, where x is a single node. Example
(all examples are taken from 4lang/Reform):

{\tt aim   purpose}

\noindent
that is, the word {\it aim} is defined as {\it purpose}. Somewhat more complex
definitions are given by a comma-separated list. Here the head is always the
first element. Examples:

\begin{verbatim}
board   artefact, long, flat    
boat    ship, small, open/1814  
\end{verbatim}

The number following the '/', if present, serves to disambiguate among various
definitions, in this case adjectival {\it open} `nyilt, apertus' from verbal
{\it open} `nyit, aperio'. These numbers are in column 5 of the 4lang file. 

\subsection{External pointers}\label{atsign}

Sometimes (here 42 cases in 1400) a concept doesn't fully belong in the
lexicon, but rather in the encyclopedia. To quote \cite{Kornai:2019} p 190:

\begin{quotation} 
While our goal is to create a formal theory of lexical definitions, it must be
acknowledged that such definitions can often elude the grasp of the linguist
and slide into a description of world knowledge of various sorts.
Lexicographic practice acknowledges this fact by providing, somewhat
begrudgingly, little pictures of flora, fauna, or plumbers’ tools. A
well-known method of avoiding the shame of publishing a picture of a yak is to
make reference to {\it Bos grunniens} and thereby point the dictionary user
explicitly to some encyclopedia where better information can be found.
\end{quotation}

In the formal language defined here, such {\it external pointers} are marked
by a prefixed @. Examples:

\begin{verbatim}
Africa	land, @Africa	
London	city, @London	
Muhammad  man/744, @Muhammad	
\end{verbatim}

\subsection{Subjects and objects}\label{subjobj}

In addition to 0 links, definitions often explain the definiendum in terms of
it being the subject or object of some binary relation. When not defined by
some more primitive term, such binary telations are given in CAPS.  For
example:

\begin{verbatim}
April   month, FOLLOW march/1563, may/1560 FOLLOW
bank    institution, money IN/2758
\end{verbatim}

\noindent
The intended graph for April will have a 0 link from the head to month, a 1
link to march/1563 and a 2 link to may/1560. Often, what is at the other side
of the binary is unspecified, in which case we use the ' symbol ``plugged
up''.  Examples:

\begin{verbatim}
vegetable  plant, ' EAT
sign  information, ' PERCEIVE, show, HAS meaning
\end{verbatim}

\noindent
Thus, {\it vegetable} is a plant that someone (not specified who) can eat (ot
is the object of eating, subject unspecified), and {\it sign} is\_a
information, is the object of perception, is\_a show (nominal, something that
is or can be shown) and has meaning.

\subsection{Direct predication}\label{isa}

In a formula {\tt A[B]} means that there is a 0-link from A to B. This is used
only to make the notation more compact. The notation B(A) means the same
thing, it is also just syntactic sugar. Both brackets and parens can contain
full subgraphs. 

\begin{verbatim}
tree fa arbor drzewo 709 N plant, HAS material[wood], HAS trunk/2759, 
                           HAS crown 
\end{verbatim}

\subsection{Defaults}\label{default}

In principle, all definitional elements are strict (can be defeased only under
exceptional circumstances) but time and again we find it expedient to collapse 
strongly related entries by means of defaults that appear in angled brackets. 

\begin{verbatim}
ride lovagol equito jez1dzic1_konno 1555 u U travel, =AGT ON <horse>, 
                                             INSTRUMENT <horse>
\end{verbatim}

These days, a more generalized {\it ride} is common ({\it riding the bus,
  catching a ride, \ldots} so the definition {\tt travel} should be sufficient
as is. The historically prevalant mode of traveling, on horesback, is kept as
a default. Note that these two entries often get translated by different
words: for example Hungarian distinguishes {\it utazik} `travel' and {\it
  lovagol} `rides a horse', a verb that cannot appear with an object or
instrument the same way as English `ride a bike' can.  

\subsection{Agents, patients}\label{agtpat}

The relationship between horseback riding (which is, as exemplified in 1.5
above, just a form of travelling) and its defining element, the horse, is
indirect. The horse is neither the subject, not the object of travel. 
Rather, it is the rider who is the subject of the definiendum and the
definiens alike, corresponding to a graph node that has a 1 arrow leading to
it from both. This node is labelled by {\tt =AGT}, so when we wish to express 
the semantic fact that Hungarian {\it lovagol} means travel on a horse we
write 

\begin{verbatim}
lovagol travel, =AGT ON horse
\end{verbatim} 

\noindent
Note that the horse is not optional for this verb in Hungarian: it is
syntactically forbidden ({\it lovagol} is intransitive) and semantically
obligatory. (Morphologically it is already expressed, as the verb is derived
from the stem {\it l\'o} `horse' though this derivation is not by productive
suffixation.) Remarkably, when the object is\_a horse (e.g. a colt is a young
horse, or a specific horse like Kincsem) we can still use {\it lovagol} as in
{\it J\'anos a csik\'ot lovagolta meg} or {\it Elijah Madden Kincsemet
  lovagolta}.

For the patient role, consider the word {\it know}, defined as `has
information about'. For this to work, the expression {\tt x know y} has to be
equivalent to {\tt x HAS information ABOUT y}. For this to work, we need to
express the fact that the subject of HAS is the same as the subject of {\it
  know} (this is done by the {\tt =AGT} placeholder) and that the object of
ABOUT is the same as the object of knowing -- this will be done by the {\tt
  =PAT} placeholder. 

\subsection{Deep cases}\label{deepcase}

Of the 1,200 initially unreduced primitives, about 15\% refer to the major
thematic roles {\tt =AGT,=PAT} discussed above. The treatment of the others
(altogether less than 10\%) is discussed here. \cite{Makrai:2014} used several 
thematic role-like constructs (numbers in the table give their occurrence
frequencies in the 1200 set):

\begin{tabular}{rr}
name & freq\\
\hline
=AGT & 178\\
=PAT & 174\\
=REL & 34\\
=POS & 26\\
=TO & 19\\
=DAT & 19\\
=FROM & 7\\
=OBL & 5\\
=FOR & 1\\
\end{tabular}

Of these, only {\tt =AGT} and {\tt =PAT} are still in use, all other thematic
role-like elements, be they deep cases, surface cases, or prepositions, have
been redefined to rely only on these, see Reform/notes.

\subsection{More complex notation}\label{parens}

When using [] or (),both can contain not just single nodes but entire
subgraphs. For subgraphs we also use \{ \}. This will have to be rethought in terms of a consistent
IRTG-friendly version of hypergraphs. Example:

\begin{verbatim}
stock document, company HAS, {person HAS stock} prove {person HAS PART_OF company}
\end{verbatim}

`stocks are documents that companies have, if a person has some stock it
proves that a person owns a part of the company'


\printbibliography

\end{document}





small grammar suitable for parsing. In the grammar, () stands for optional,
$|$ stands for choice, and $^*$ for one or more.

weight  physical(quantity), heavy
water  liquid, HAS lack(colour), HAS lack(taste), HAS lack(smell), life NEED
\end{verbatim}

\subsection{Iterated links} 

The definition graph will often have subgraphs denoted as one. In such cases,
parentheses are used with the lead predicate. Examples: 

\begin{verbatim}
weight  physical(quantity), heavy
water  liquid, HAS lack(colour), HAS lack(taste), HAS lack(smell), life NEED
\end{verbatim}



\noindent
Definition $\rightarrow$ Definiendum Definiens (\% Comment)\\
Definiendum $\rightarrow$ Atom\\
Definiens $\rightarrow$ Clause ('','' Clause)$^*$\\
Comment  $\rightarrow$ (Arbitrary string)\\
Atom  $\rightarrow$ PlainAtom$|$NumberedAtom\\
NumberedAtom  $\rightarrow$ PlainAtom''/''Number\\
Clause  $\rightarrow$ 0Clause$|$1Clause''|''2Clause|ComplexClause\\
0Clause  $\rightarrow$ Atom\\
1Clause  $\rightarrow$ BIN '\\
2Clause   $\rightarrow$ ' BIN\\
ComplexClause  $\rightarrow$ Atom(Clause)

\end{document}



Here we introduce some terminology by paraphrase, describing the intended
meaning before offering more formal definitions. Our goal is to stay close to
the standard meaning of these terms, but we do not intend to fully recreate
every aspect of the theories where they originate. 

{\bf Atoms} are intended in the original sense of Democritus, to be small,
indivisible, indestructible units. They are the building blocks of solid
physical objects, but (i) it's not enough to have atoms to have a physical
object, you also need some kind of glue to hold them together and (ii) we
permit other physical objects which are not atomic, in particular liquids and
gases/emanations of various sorts (think of force fields or sounds) which are
thought of as infinitely divisible. Atoms come in a few predefined sortal
types. [We don't do modern physics, quarks, etc. and flatly ignore the fact
  that what contemprary language calls atoms are divisible and desctructible.]

{\bf Space} is ordinary 3D Euclidean space, {\bf time} will generally be
considered discrete (so that the arrow paradox etc. need full
discussion). Liquids and gases may fill various volumes but need not be
stationary even in a closed volume, and can have varying density. 

{\bf Objects} are given by their atoms and some glue relations that hold them
together. Objects can have various properties, such as shape, color,
temperature, taste etc. Certain properties are like liquids or gases
infusing/pervading the object (temperature, density), others (shape in
particular) pertain to their boundaries, yet others can be imperceptible
(e.g. being expensive, being cursed, etc).

There can be various (n-place) {\bf relations} obtaining between objects but,
importantly, relations can also hold between things {\it construed as}
objects, such as geometrical points with no atomic content, e.g. the corner of
the room {\it is next to} the window', complex motion predicates, e.g. `the
flood {\it caused} the breaking of the dam', and so on. Arguments of relations
will be called {\bf matters}, but they need not be material. One particularly
important relation is {\bf identity in essence, idest}, which can hold across
time between objects (including solids) even if they are not atom-by-atom
identical. The idest relation we are interested in is the relation holding
between anaphors and their antecedents, as in {\it Kim cooked dinner$_i$ and
  Sandy ate it$_i$}. This normally assumes a preponderance of atoms staying
identical, but there are important exceptions, as in {\it Our weekend sailboat
  was completely destroyed by fire but we rebuilt it}, where construal
identity overrides physical identity. Note that idest is not transitive,
because it requires a vantage point, and if A idest B from vantage P and B
idest C from vantage Q, there is no guarantee that there is an R such that A
idest C from vantage R. Note also that our interest in idest comes mostly
from establishing the vantage argument that's implicit in it. 

We do not follow situation theory \citep{Barwise:1983,Devlin:1991} closely,
but we do retain some of the techniques, and much of the motivation (reasoning
about common-sense and real world situations).  For us, a {\bf situation} is
composed of some matters (these may include emotions, intentions, and all
kinds of intangibles that exist only in the mind of some observer) and some
relations (which again may be purely notional ones like `forming a
triangle'). None of the relational tuples are negative.

Compared to the basic sortal types used in situation theory, we will have {\bf
  location}, conceived of connected subsets (in the limiting case, points,
lines, or surfaces) in 3D Euclidean space, but also including
nonexistent/inaccessible notional locations like {\it Heaven}. We note that
locations, both spatial and temporal, are subject to the same loose identity
conditions as the idest we discussed above for objects. We will also make use
of the {\bf individual} type, again making room for nonexistent/inaccessible
individuals as well as notional ones (e.g. personifications of countries or
emotions). We will have no use for types necessitated by the technical
machinery of situation theory such as PARamater, POLarity, or TYPe, nor will
we use infons. Even the use of RELn (n-place relations) will be different, as
we have seemingly n-place relations that have hidden variables, so are
actually m-place reations, and this includes the case when we can't easily
name (or quantify over) these variables.

Altogether, we assume a large number (about $10^5$) of ur-objects, roughly one
per morpheme or word, some of them defeasibly typed as LOC (location) or PER
(a special type of individual, a {\bf person}). In addition to these, we will
have a few technical elements such as the empty node $\cdot$, three directed
connectives `0' (is, isa); `1' (subject); and `2' (object). {\bf truth
  values} from a small set $B$ (not necessarily a boolean algebra), and {\bf
  scores} from a small linear order $L$.

The directed connectives are conceptualized as colored edges from nodes to
nodes or larger structures in a graph. The graphs are built up recursively:
(i) urelements, including the empty node, are simple graphs, with their one
element considered their root. (ii) a simple node x, with a 0/1/2 numbered
link to another graph, is a complex graph with root x. (iii) A complex graph,
with root x, with a 0/1/2 numbered link {\it from its root} is again a graph,
with root x.

To each graph corresponds a {\bf formula} built up in a similar fashion:
urelements (including the empty element) are simple formulas headed by
themselves, if f is a simple formula and F a formula, f0F, f1F, and f2F are
complex formulas, still headed by f, and if xrC is a complex formula headed by
x (here r is metalinguistic abbreviation for 0,1,2) and G some other complex
formula, xrC0G, xrC1G, and xrC2G are again complex formulas.

{\bf Valuations} are partial mappings from graphs (or, equivalently, from
formulas) to $L$. There is no analogous `truth assignment' because in the
inner models that are central to the theory, everything is true by virtue of
being present. On occasion we may be able to reason based on missing
signifiers, the dog that didn't bark, but this is atypical and left for later
study. A {\bf situation} is simply a (conjunctive) collection of
formulas/graphs. Whether we need to consider a fixed valuation as part of the
situation will be discussed later. 

A formula of the form x1a2b is equivalent to x2b1a, both mean in traditional
terms that x is a binary relation whose first argument is a and the second b.
As syntactic sugar, these could be written axb, but once we do this, we need
parentheses so the price of the sugar may be too high. As a compromise, binary
connectives of the kind we are interested in (these come from a small, closed
list that has spatial AT, IN, OVER, SOURCE, GOAL, temporal BEFORE and AFTER,
possessive HAS, and perhas a handful of others like CAUSE or INSTRUMENT) are
given in small caps, and will be written infix. So `breakfast BEFORE shower'
abbreviates before1breakfast2shower or the equivalent before2shower1breakfast
and we will say that in such cases the formula has a {\bf main connective}
x. Note that not all formulas have main connectives in this sense.  (Another
set of sugary devices concerns reification of missing arguments, especially in
relative clauses, these will not be discussed here.)  An {\bf unfolding
  situation} is one where the formulas include statements with main
connectives BEFORE or AFTER (one of these two could be eliminated, but this is
not exciting).

{\it Extension} of a situation can be by adding further formulas (this is
standard), and more importantly, by adding further specifications to existing
formulas. One of these is adding further, hitherto unspecified arguments to
the formulas already in a situation, for example `the guttersnipe killed the
officer {\it with a long-range gun}' extends kill1guttersnipe2officer to kill
INSTR lrg, which would be, if we undo the syntactic sugar,
instr1kill1guttersnipe2officer2lrg Note that this kind of elaboration leaves
the two situations (with or without the instrument clause) idest, but it may
change the valuation. 



\section{Definitions}


{\bf Definition 1.} A model instance is a collection of finitely many {\it
  reachable} objects and an unspecified number (possibly zero) of {\it
  unreachable} ones. It is assigned a rational number called its {\it
  timestamp}. Here and in what follows `object' is a term neutral between what
are traditionally considered objects (e.g. a table) and what are traditionally
called `events' e.g. a soccer match.  \andras{More on atomic and compound
  objects}

{\bf Definition 2.} {\it Unary} terms select a subset (possibly empty) of
objects in each model instance. For example, {\it person(x)} selects those
objects that are people (reachable in all but human-uninhabited models),
whereas {\it unicorn(x)} selects only unreachable objects (reachable only
in fictional/mythical models).

{\it Binary} terms, written infix, are directed graph edges connecting two
objects/terms.  For example {\it dream\_of} is a binary term connecting a word
to an object and {\it Kim dream\_of unicorn} is an edge, colored `dream\_of',
between a (possibly reachable) object {\it Kim} and a (possibly unreachabe)
object {\it unicorn}. Note that edges can terminate (and/or start) in other
edges as well, as in {\it Kim dream\_of eat icecream} where the end of the
{\it dream\_of} edge is the edge (Kim eat icecream). 

\section{Preliminaries}

We need two special relations, {\it name}, and {\it exist}, and two special
types, {\it object} and {\it expression}. Expressions (words and more complex
linguistic expressions) are mapped by the interpretation relation to terms.
Some objects have names, many don't. An unreachable object can also have a
name. `Bilbo never heard of Palantir' is true. 


\section{Temporal structure}
 We need to define a model stream (list of instances with increasing
 timestamps, largely invariant objects, and  causal continuity).

  know =AGT HAS information, information ABOUT =PAT
